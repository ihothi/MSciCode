{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from ProjectF import MLAData,classification, Object,storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading in data\n",
    "PlateDir = os.path.normpath(\"D:\\Data\\Plate_Name.txt\")\n",
    "with open(PlateDir) as f:\n",
    "    Spectra_Files = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PLATEIDs = []\n",
    "BinInfos = []\n",
    "Flux = []\n",
    "MJDs = []\n",
    "TrainingDir = os.path.normpath(\"D:\\Data\")\n",
    "TrainingFolder =  os.path.normpath(\"\\Training\")\n",
    "slash =  os.path.normpath(\"\\\\\")\n",
    "for spectrum in Spectra_Files:\n",
    "    plate_ = fits.open( TrainingDir +TrainingFolder+slash+ spectrum ,memmap=True)\n",
    "    Bin_info_ = plate_[5].data\n",
    "    Flux_ = plate_[0].data\n",
    "    primhdu_ = plate_[0]\n",
    "    PLATEIDs.append(primhdu_.header['PLATEID'])\n",
    "    MJDs.append(primhdu_.header['MJD'])\n",
    "    BinInfos.append(Bin_info_)\n",
    "    Flux.append(Flux_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list = fits.open(TrainingDir+slash+'Superset_DR12Q.fits',memmap=True)#opening file\n",
    "\n",
    "supers=list[1].data # storing  BINTABLE extension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Full_Data = storing(PLATEIDs,supers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y,Train_z, Train_mag = MLAData(Full_Data,BinInfos,Flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spPlate-4791-55889.fits',\n",
       " 'spPlate-6970-56444.fits',\n",
       " 'spPlate-5852-56034.fits']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestPlateDir = os.path.normpath(\"D:\\Data\\TestPlate_Name.txt\")\n",
    "with open(TestPlateDir) as f:\n",
    "    Spectra_TestFiles = f.read().splitlines()\n",
    "Spectra_TestFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainingDir = os.path.normpath(\"D:\\Data\")\n",
    "TestingFolder =  os.path.normpath(\"\\Test\")\n",
    "PLATEIDs_test = []\n",
    "BinInfos_test = []\n",
    "Flux_test = []\n",
    "z=0\n",
    "for spectrum_test in Spectra_TestFiles:\n",
    "    plate_test = fits.open(spectrum_test ,memmap=True)\n",
    "    Bin_info_test = plate_test[5].data\n",
    "    Flux_t = plate_test[0].data\n",
    "    primhdu_test = plate_test[0]\n",
    "    PLATEIDs_test.append(primhdu_test.header['PLATEID'])\n",
    "    BinInfos_test.append(Bin_info_test)\n",
    "    Flux_test.append(Flux_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Full_Data_test = storing(PLATEIDs_test,supers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test,Y_test,All_redshifts,All_Mag = MLAData(Full_Data_test,BinInfos_test,Flux_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hiddenlayer_format = (13)\n",
    "backprop_method = 'lbfgs'\n",
    "lr=0.00001\n",
    "act = 'tanh'\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hiddenlayer_format,max_iter=500, solver = 'lbfgs',learning_rate_init=lr,activation=act) ##Think About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=13, learning_rate='constant',\n",
       "       learning_rate_init=1e-05, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(X)  \n",
    "X = scaler.transform(X)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "mlp.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.61      0.63       225\n",
      "          3       0.73      0.76      0.74       413\n",
      "          4       0.14      0.13      0.14        15\n",
      "         30       0.05      0.05      0.05        42\n",
      "\n",
      "avg / total       0.65      0.65      0.65       695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "star = classification(1,Y_test,predictions)\n",
    "qso = classification(3,Y_test,predictions)\n",
    "gal = classification(4,Y_test,predictions)\n",
    "bal = classification(30,Y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter File name: FullRun1\n"
     ]
    }
   ],
   "source": [
    "File_Name = input(\"Please Enter File name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = open(TrainingDir+slash+File_Name+\".txt\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1=[\"Files used to train: \",np.str(Spectra_Files), \"\\n\"]\n",
    "sp= \"\\n\"\n",
    "t2 = [\"Files used to test: \",np.str(Spectra_TestFiles), \"\\n\"]\n",
    "t3 = [\"Number of training objects = \",,np.str(len(Spectra_Files)), \"\\n\"]\n",
    "t4 = [\"Number of testing objects = \",,np.str(len(Spectra_TestFiles)), \"\\n\"]\n",
    "n1 = [\"Structure of neural network: \", np.str(hiddenlayer_format),\"\\n\"]\n",
    "n2  = [\"Backpropagation method used: \",np.str(backprop_method), \"\\n\"]\n",
    "n3  = [\"Learning rate: \",np.str(lr), \"\\n\"]\n",
    "n4  = [\"Activation Function: \",np.str(act), \"\\n\"]\n",
    "r1 = [\"Results of Neural Network: \", \"\\n\",\"\\n\"]\n",
    "r2=[\"        \",\" Star    Quasar  Galaxy  BAL \",\"\\n\",]\n",
    "r3=\"Star     \",np.str(np.round(star[0]*100,2)),\"%  \", np.str(np.round(star[1]*100,2)),\"%  \",np.str(np.round(star[2]*100,2)),\"%  \",np.str(np.round(star[3]*100,2)),\"%\",\"\\n\"\n",
    "r4=\"Quasar   \",np.str(np.round( qso[0]*100,2)),\"%  \", np.str(np.round( qso[1]*100,2)),\"%  \",np.str(np.round( qso[2]*100,2)),\"%  \",np.str(np.round( qso[3]*100,2)),\"%\",\"\\n\"\n",
    "r5=\"Galaxy   \",np.str(np.round( gal[0]*100,2)),\"%  \", np.str(np.round( gal[1]*100,2)),\"%  \",np.str(np.round( gal[2]*100,2)),\"%  \",np.str(np.round( gal[3]*100,2)),\"%\",\"\\n\"\n",
    "r6=\"BAL      \",np.str(np.round( bal[0]*100,2)),\"%  \", np.str(np.round( bal[1]*100,2)),\"%  \",np.str(np.round( bal[2]*100,2)),\"%  \",np.str(np.round (bal[3]*100,2)),\"%\",\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.writelines(t1)\n",
    "d.writelines(sp)\n",
    "d.writelines(t2)\n",
    "d.writelines(sp\n",
    "d.writelines(t3)\n",
    "d.writelines(t4)\n",
    "d.writelines(sp)\n",
    "d.writelines(sp)\n",
    "d.writelines(n1)\n",
    "d.writelines(n2)\n",
    "d.writelines(n3)\n",
    "d.writelines(n4)\n",
    "d.writelines(sp)\n",
    "d.writelines(sp)\n",
    "d.writelines(r1)\n",
    "d.writelines(r2)\n",
    "d.writelines(r3)\n",
    "d.writelines(r4)\n",
    "d.writelines(r5)\n",
    "d.writelines(r6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: Accessing an HDU after an HDUList is closed, where\n",
      "that HDU was no read while the HDUList was open\n",
      "is deprecated.  That is, you did something like:\n",
      "\n",
      "    >>> hdulist.close()\n",
      "    >>> print(hdulist[2].header)\n",
      "\n",
      "even though hdulist[2] had not been read yet.  Instead\n",
      "do:\n",
      "\n",
      "    >>> print(hdulist[2].header)\n",
      "    >>> hdulist.close()\n",
      "\n",
      "or open the file with lazy_load_hdus=False to read all\n",
      "the HDUs into memory immediately upon opening the file.\n",
      " [astropy.io.fits.hdu.hdulist]\n"
     ]
    }
   ],
   "source": [
    "list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
