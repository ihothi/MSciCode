{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from ProjectF import MLAData,classification, Object,storing,MLADataBin\n",
    "import random\n",
    "\n",
    "## Loading in data\n",
    "PlateDir = os.path.normpath(\"D:\\Data\\Plate_Name_Reduced.txt\")\n",
    "with open(PlateDir) as f:\n",
    "    Spectra_Files = f.read().splitlines()\n",
    "print('Yes')  \n",
    "PLATEIDs = []\n",
    "BinInfos = []\n",
    "Flux = []\n",
    "MJDs = []\n",
    "log_wavst=[]\n",
    "ORMASK=[]\n",
    "ANDMASK=[]\n",
    "INVAR=[]\n",
    "\n",
    "TrainingDir = os.path.normpath(\"D:\\Data\")\n",
    "slash =  os.path.normpath(\"\\\\\")\n",
    "TrainingFolder =  os.path.normpath(\"\\Training\")\n",
    "slash =  os.path.normpath(\"\\\\\")\n",
    "for spectrum in Spectra_Files:\n",
    "    plate_ = fits.open( TrainingDir +TrainingFolder+slash+ spectrum ,memmap=True)\n",
    "    Bin_info_ = plate_[5].data\n",
    "    Flux_ = plate_[0].data\n",
    "    primhdu_ = plate_[0]\n",
    "    PLATEIDs.append(primhdu_.header['PLATEID'])\n",
    "    ORMASK.append( plate_[3].data)\n",
    "    ANDMASK.append( plate_[2].data)\n",
    "    INVAR.append( plate_[1].data)\n",
    "    log_wavst.append(primhdu_.header['COEFF0'])\n",
    "    MJDs.append(primhdu_.header['MJD'])\n",
    "    BinInfos.append(Bin_info_)\n",
    "    Flux.append(Flux_)\n",
    "    \n",
    "list = fits.open(TrainingDir+slash+'Superset_DR12Q.fits',memmap=True)#opening file\n",
    "print(len(log_wavst))\n",
    "supers=list[1].data # storing  BINTABLE extension data\n",
    "\n",
    "Full_Data = storing(PLATEIDs,supers)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y,Train_z, Train_mag,wavst = MLAData(Full_Data,BinInfos,Flux, log_wavst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "#while i <len(PLATEIDs):\n",
    "C_Plate = PLATEIDs[i]\n",
    "a1 = X[i] \n",
    "a2 = np.array(Y[i])\n",
    "col1 = fits.Column(name='Bin_Flux', format='PJ()', array=np.array(a1,dtype=np.object))\n",
    "col2 = fits.Column(name='Class', format='I', array=a2)\n",
    "cols = fits.ColDefs([col1, col2])\n",
    "tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "print(tbhdu.data)\n",
    "tbhdu.writeto(TrainingDir+slash+np.str(C_Plate)+'.fits')\n",
    "i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_Size=3\n",
    "X_bin,Y_bin,Train_z_bin, Train_mag_bin,wavst_bin = MLADataBin(Full_Data,BinInfos,Flux,log_wavst, ANDMASK, INVAR, BIN_Size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i <len(PLATEIDs):\n",
    "    C_Plate = PLATEIDs[i]\n",
    "    a1 = X_bin[i] \n",
    "    a2 = np.array(Y_bin[i])\n",
    "    col1 = fits.Column(name='Bin_Flux', format='PJ()', array=np.array(a1,dtype=np.object))\n",
    "    col2 = fits.Column(name='Class', format='I', array=a2)\n",
    "    cols = fits.ColDefs([col1, col2])\n",
    "    tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "    tbhdu.writeto(TrainingDir+slash+\"rebinned\"+np.str(C_Plate)+'.fits')\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
