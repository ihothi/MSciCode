{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925\n",
      "4011\n",
      "4024\n",
      "4041\n",
      "4061\n",
      "4090\n",
      "4177\n",
      "D:\\share\\data1\\boss_data\\sas\\dr12\\boss\\spectro\\redux\\v5_7_0\\3925\\spPlate-3925-55338.fits\n",
      "D:\\share\\data1\\boss_data\\sas\\dr12\\boss\\spectro\\redux\\v5_7_0\\4011\\spPlate-4011-55635.fits\n",
      "D:\\share\\data1\\boss_data\\sas\\dr12\\boss\\spectro\\redux\\v5_7_0\\4024\\spPlate-4024-55646.fits\n",
      "D:\\share\\data1\\boss_data\\sas\\dr12\\boss\\spectro\\redux\\v5_7_0\\4041\\spPlate-4041-55361.fits\n",
      "D:\\share\\data1\\boss_data\\sas\\dr12\\boss\\spectro\\redux\\v5_7_0\\4061\\spPlate-4061-55362.fits\n",
      "D:\\share\\data1\\boss_data\\sas\\dr12\\boss\\spectro\\redux\\v5_7_0\\4090\\spPlate-4090-55500.fits\n",
      "D:\\share\\data1\\boss_data\\sas\\dr12\\boss\\spectro\\redux\\v5_7_0\\4177\\spPlate-4177-55688.fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from ProjectF import MLAData,classification, Object,storing,MLADataBin\n",
    "import random\n",
    "slash =  os.path.normpath(\"\\\\\")\n",
    "Platedir = os.path.normpath(\"D:\"+slash+\"share\"+slash+\"data1\"+slash+\"boss_data\"+slash+\"sas\"+slash+\"dr12\"+slash+\"boss\"+slash+\"spectro\"+slash+\"redux\"+slash+\"v5_7_0\")\n",
    "\n",
    "plate_name = os.listdir(Platedir)\n",
    "file=\"FullPlate_Name.txt\"\n",
    "p = open(file, 'w')\n",
    "for i in plate_name:\n",
    "    print(i)\n",
    "    p.write(i +'\\n')\n",
    "\n",
    "p.close()\n",
    "print(\"opening files to store\")\n",
    "with open(file) as f:\n",
    "    Spectra_Files = f.read().splitlines() \n",
    "PLATEIDs = []\n",
    "BinInfos = []\n",
    "Flux = []\n",
    "MJDs = []\n",
    "log_wavst=[]\n",
    "ORMASK=[]\n",
    "ANDMASK=[]\n",
    "INVAR=[]\n",
    "\n",
    "for f in Spectra_Files:\n",
    "    file_list = os.listdir(Platedir+slash+f)\n",
    "    for l in file_list:\n",
    "        if 'spPlate' in l and \".fits\"in l: \n",
    "            c=Platedir+slash+f+slash+l\n",
    "            print(c)\n",
    "            plate_ = fits.open(c,memmap=True)\n",
    "            Bin_info_ = plate_[5].data\n",
    "            Flux_ = plate_[0].data\n",
    "            primhdu_ = plate_[0]\n",
    "            PLATEIDs.append(primhdu_.header['PLATEID'])\n",
    "            ORMASK.append( plate_[3].data)\n",
    "            ANDMASK.append( plate_[2].data)\n",
    "            INVAR.append( plate_[1].data)\n",
    "            log_wavst.append(primhdu_.header['COEFF0'])\n",
    "            MJDs.append(primhdu_.header['MJD'])\n",
    "            BinInfos.append(Bin_info_)\n",
    "            Flux.append(Flux_)\n",
    "        \n",
    "list = fits.open('Superset_DR12Q.fits',memmap=True)#opening file\n",
    "supers=list[1].data # storing  BINTABLE extension data\n",
    "print(\"Storing Data\")\n",
    "Full_Data = storing(PLATEIDs,supers)\n",
    "X,Y,Train_z, Train_mag,And, In, wavst, ID = MLAData(Full_Data,BinInfos,Flux, log_wavst,ANDMASK,INVAR)\n",
    "\n",
    "i=0\n",
    "while i <len(PLATEIDs):\n",
    "    C_Plate = PLATEIDs[i]\n",
    "    a1 = X[i] \n",
    "    a2 = np.array(Y[i])\n",
    "    if len(a1)==0 & len(a2)==0:\n",
    "        i=i+1\n",
    "    else: \n",
    "        a3=And[i]\n",
    "        a4=In[i]\n",
    "        a5 = Train_z[i]\n",
    "        a6=ID[i]\n",
    "        a7 = wavst[i]\n",
    "        col1 = fits.Column(name='Bin_Flux', format='PD()', array=np.array(a1,dtype=np.object))\n",
    "        col2 = fits.Column(name='Class', format='I', array=np.array(a2))\n",
    "        col3 = fits.Column(name='ANDMASK', format='PD()', array=np.array(a3,dtype=np.object))\n",
    "        col4 = fits.Column(name='INVAR', format='PD()', array=np.array(a4,dtype=np.object))\n",
    "        col5 = fits.Column(name='Redshift', format='D', array=np.array(a5))\n",
    "        col6 = fits.Column(name='Name', format='20A', array=np.array(a6))\n",
    "        cols = fits.ColDefs([col1, col2,col3, col4,col5,col6])\n",
    "        tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "        prihdr = fits.Header()\n",
    "        prihdr['Plate'] = C_Plate\n",
    "        prihdr['LogWav'] = a7\n",
    "        prihdu = fits.PrimaryHDU(header=prihdr)\n",
    "        file_name = \"restore\"+\"/\"+np.str(C_Plate)+'.fits'\n",
    "        thdulist = fits.HDUList([prihdu, tbhdu])\n",
    "        thdulist.writeto(file_name)\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
