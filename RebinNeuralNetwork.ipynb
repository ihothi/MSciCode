{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from ProjectF import MLAData,classification, Object,storing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = np.str(10)\n",
    "TrainingDir = os.path.normpath(\"D:\\Data\")\n",
    "slash =  os.path.normpath(\"\\\\\")\n",
    "TrainingFolder =  os.path.normpath(\"\\Training\")\n",
    "PlateDir =\"D:\"+slash+\"Data\"+slash+\"FullRebin10\"+\".txt\"\n",
    "with open(PlateDir) as f:\n",
    "    Spectra_Files = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_log=[]\n",
    "Full_table = []\n",
    "PLATEIDs = []\n",
    "for spectrum in Spectra_Files:\n",
    "    plate_ = fits.open( TrainingDir+slash+'rebin'+slash+spectrum ,memmap=True)\n",
    "    primhdu_ = plate_[0]\n",
    "    hdu =  plate_[1].data\n",
    "    Full_table.append(hdu)\n",
    "    PLATEIDs.append(primhdu_.header['Plate'])\n",
    "    wav_log.append(primhdu_.header['LogWav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_r  = []\n",
    "plate_n  = []\n",
    "plate_c  = []\n",
    "plate_x  = []\n",
    "plate_y  = []\n",
    "i = 0\n",
    "while i < len(PLATEIDs):\n",
    "    plate_hdu  = Full_table[i]\n",
    "    obj = 0\n",
    "    while obj <len(plate_hdu):\n",
    "        currentobj = plate_hdu[obj]\n",
    "        Currentplate_z = currentobj[4]\n",
    "        Currentplate_y = currentobj[2]\n",
    "        Currentplate_x = currentobj[1]\n",
    "        Currentplate_n = currentobj[0]\n",
    "        plate_r.append(Currentplate_z)\n",
    "        plate_n.append(Currentplate_n)\n",
    "        plate_x.append(Currentplate_x[:800])\n",
    "        plate_y.append(Currentplate_y)\n",
    "        obj = obj +1\n",
    "    i = i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hiddenlayer_format = (13)\n",
    "backprop_method = 'lbfgs'\n",
    "lr=0.00001\n",
    "act =  'logistic'#'tanh'\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hiddenlayer_format,max_iter=500, solver = backprop_method,learning_rate_init=lr,activation=act) ##Think About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plate_x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=13, learning_rate='constant',\n",
       "       learning_rate_init=1e-05, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(np.array(plate_x))  \n",
    "plate_x = scaler.transform(plate_x)    \n",
    "mlp.fit(plate_x,plate_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainingDir = os.path.normpath(\"D:\\Data\")\n",
    "slash =  os.path.normpath(\"\\\\\")\n",
    "TrainingFolder =  os.path.normpath(\"\\Training\")\n",
    "PlateDir =\"D:\"+slash+\"Data\"+slash+\"FullTest10.txt\"\n",
    "with open(PlateDir) as f:\n",
    "    Spectra_TestFiles = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_log_Test=[]\n",
    "Full_table_Test = []\n",
    "PLATEID_Test = []\n",
    "for spectrum in Spectra_TestFiles:\n",
    "    plate_test = fits.open( TrainingDir+slash+'rebintrain'+slash+spectrum ,memmap=True)\n",
    "    primhdu_test = plate_[0]\n",
    "    hdu =  plate_test[1].data\n",
    "    Full_table_Test.append(hdu)\n",
    "    PLATEID_Test.append(primhdu_.header['Plate'])\n",
    "    wav_log_Test.append(primhdu_.header['LogWav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plate_rt = []\n",
    "plate_nt = []\n",
    "plate_ct = []\n",
    "plate_xt = []\n",
    "plate_yt = []\n",
    "i = 0\n",
    "while i < len(PLATEID_Test):\n",
    "    plate_hdu  = Full_table[i]\n",
    "    obj = 0\n",
    "    while obj <len(plate_hdu):\n",
    "        currentobj = plate_hdu[obj]\n",
    "        Currentplate_z = currentobj[4]\n",
    "        Currentplate_y = currentobj[2]\n",
    "        Currentplate_x = currentobj[1]\n",
    "        Currentplate_n = currentobj[0]\n",
    "        plate_rt.append(Currentplate_z)\n",
    "        plate_nt.append(Currentplate_n)\n",
    "        plate_xt.append(Currentplate_x[:800])\n",
    "        plate_yt.append(Currentplate_y)\n",
    "        obj = obj +1\n",
    "    i = i+1\n",
    "\n",
    "plate_xt = scaler.transform(plate_xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(np.array(plate_xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       745\n",
      "          3       0.58      0.40      0.47       291\n",
      "          4       0.68      0.25      0.37        51\n",
      "         30       0.64      0.68      0.66       658\n",
      "\n",
      "avg / total       0.66      0.67      0.66      1745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test=plate_yt\n",
    "print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "star,star_starloc,star_lowzloc,star_galloc,star_highzloc = classification(1,Y_test,predictions) \n",
    "lowz,lowz_starloc,lowz_loc,lowz_galloc,lowz_highzloc = classification(3,Y_test,predictions)\n",
    "gal,gal_starloc,gal_lowzloc,gal_galloc,gal_highzloc = classification(4,Y_test,predictions)\n",
    "highz,highz_starloc,highz_lowzloc,highz_galloc,highz_highzloc = classification(30,Y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter File name: 05.12.17_4\n"
     ]
    }
   ],
   "source": [
    "File_Name = input(\"Please Enter File name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = open(TrainingDir+slash+File_Name+\"rebin\"+bin_size+\".txt\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1=[\"Files used to train: \",np.str(Spectra_Files), \"\\n\"]\n",
    "sp= \"\\n\"\n",
    "t2 = [\"Files used to test: \",np.str(Spectra_TestFiles), \"\\n\"]\n",
    "t3 = [\"Number of training objects = \",np.str(len(Spectra_Files)), \"\\n\"]\n",
    "t5 = [\"Number of testing objects = \",np.str(len(Spectra_TestFiles)), \"\\n\",\"\\n\"]\n",
    "t4 = [\"Bin Size = \",bin_size, \"\\n\"]\n",
    "n1 = [\"Structure of neural network: \", np.str(hiddenlayer_format),\"\\n\"]\n",
    "n2  = [\"Backpropagation method used: \",np.str(backprop_method), \"\\n\"]\n",
    "n3  = [\"Learning rate: \",np.str(lr), \"\\n\"]\n",
    "n4  = [\"Activation Function: \",np.str(act), \"\\n\"]\n",
    "r1 = [\"Results of Neural Network: \", \"\\n\",\"\\n\"]\n",
    "r2=[\"        \",\"       Star    z<2.1   Galaxy   z>2.1 \",\"\\n\",]\n",
    "r3=\"Star           \",np.str(np.round(star[0]*100,2)),\"%  \", np.str(np.round(star[1]*100,2)),\"%  \",np.str(np.round(star[2]*100,2)),\"%  \",np.str(np.round(star[3]*100,2)),\"%\",\"\\n\"\n",
    "r4=\"Quasar z<2.1   \",np.str(np.round( lowz[0]*100,2)),\"%  \", np.str(np.round( lowz[1]*100,2)),\"%  \",np.str(np.round( lowz[2]*100,2)),\"%  \",np.str(np.round( lowz[3]*100,2)),\"%\",\"\\n\"\n",
    "r5=\"Galaxy         \",np.str(np.round( gal[0]*100,2)),\"%  \", np.str(np.round( gal[1]*100,2)),\"%  \",np.str(np.round( gal[2]*100,2)),\"%  \",np.str(np.round( gal[3]*100,2)),\"%\",\"\\n\"\n",
    "r6=\"Quasar z>2.1   \",np.str(np.round( highz[0]*100,2)),\"%  \", np.str(np.round( highz[1]*100,2)),\"%  \",np.str(np.round( highz[2]*100,2)),\"%  \",np.str(np.round (highz[3]*100,2)),\"%\",\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.writelines(t1)\n",
    "d.writelines(sp)\n",
    "d.writelines(t2)\n",
    "d.writelines(sp)\n",
    "d.writelines(t3)\n",
    "d.writelines(t4)\n",
    "d.writelines(t5)\n",
    "d.writelines(sp)\n",
    "d.writelines(sp)\n",
    "d.writelines(n1)\n",
    "d.writelines(n2)\n",
    "d.writelines(n3)\n",
    "d.writelines(n4)\n",
    "d.writelines(sp)\n",
    "d.writelines(sp)\n",
    "d.writelines(r1)\n",
    "d.writelines(r2)\n",
    "d.writelines(r3)\n",
    "d.writelines(r4)\n",
    "d.writelines(r5)\n",
    "d.writelines(r6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
